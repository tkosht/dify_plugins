===== ruff_check =====
CMD: uv run ruff check /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider
UP035 [*] Import from `collections.abc` instead: `Iterable`
 --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/internal/messages.py:4:1
  |
3 | import json
4 | from typing import Any, Iterable
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |
help: Import from `collections.abc`

E501 Line too long (90 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/internal/payloads.py:79:89
   |
77 |             schema_value = response_format.get("json_schema", json_schema)
78 |             if schema_value is None:
79 |                 raise ValueError("response_format=json_schema requires valid json_schema")
   |                                                                                         ^^
80 |             payload.setdefault("text", {})["format"] = _normalize_json_schema(schema_value)
81 |             return
   |

E501 Line too long (91 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/internal/payloads.py:80:89
   |
78 |             if schema_value is None:
79 |                 raise ValueError("response_format=json_schema requires valid json_schema")
80 |             payload.setdefault("text", {})["format"] = _normalize_json_schema(schema_value)
   |                                                                                         ^^^
81 |             return
   |

E501 Line too long (89 > 88)
   --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/internal/payloads.py:120:89
    |
118 |             payload[key] = value
119 |
120 |     if payload.get("max_output_tokens") is None and params.get("max_tokens") is not None:
    |                                                                                         ^
121 |         payload["max_output_tokens"] = params["max_tokens"]
    |

I001 [*] Import block is un-sorted or un-formatted
  --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/llm.py:1:1
   |
 1 | / from __future__ import annotations
 2 | |
 3 | | import json
 4 | | import urllib.error
 5 | | import urllib.request
 6 | | from dataclasses import dataclass
 7 | | from typing import Any, Generator, Iterable, Iterator
 8 | |
 9 | | from ...internal.credentials import responses_endpoint
10 | | from ...internal.errors import format_runtime_error
11 | | from ...internal.messages import extract_output_text, extract_tool_calls, to_responses_input
12 | | from ...internal.payloads import build_responses_payload
13 | | from ...provider.openai_responses_provider import OpenAIResponsesProvider
   | |_________________________________________________________________________^
14 |
15 |   try:
   |
help: Organize imports

UP035 [*] Import from `collections.abc` instead: `Generator`, `Iterable`, `Iterator`
 --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/llm.py:7:1
  |
5 | import urllib.request
6 | from dataclasses import dataclass
7 | from typing import Any, Generator, Iterable, Iterator
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
8 |
9 | from ...internal.credentials import responses_endpoint
  |
help: Import from `collections.abc`

E501 Line too long (92 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/llm.py:11:89
   |
 9 | from ...internal.credentials import responses_endpoint
10 | from ...internal.errors import format_runtime_error
11 | from ...internal.messages import extract_output_text, extract_tool_calls, to_responses_input
   |                                                                                         ^^^^
12 | from ...internal.payloads import build_responses_payload
13 | from ...provider.openai_responses_provider import OpenAIResponsesProvider
   |

E501 Line too long (94 > 88)
   --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/llm.py:100:89
    |
 98 |         return self._invoke_once(credentials, payload)
 99 |
100 |     def _invoke_once(self, credentials: dict[str, Any], payload: dict[str, Any]) -> LLMResult:
    |                                                                                         ^^^^^^
101 |         response = self._post_json(credentials, payload)
102 |         assistant_message: dict[str, Any] = {
    |

E501 Line too long (89 > 88)
   --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/llm.py:130:89
    |
128 |                 continue
129 |
130 |             if event_type in {"response.output_item.added", "response.output_item.done"}:
    |                                                                                         ^
131 |                 item = event.get("item")
132 |                 if isinstance(item, dict) and item.get("type") in {"function_call", "tool_call"}:
    |

E501 Line too long (97 > 88)
   --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/llm.py:132:89
    |
130 |             if event_type in {"response.output_item.added", "response.output_item.done"}:
131 |                 item = event.get("item")
132 |                 if isinstance(item, dict) and item.get("type") in {"function_call", "tool_call"}:
    |                                                                                         ^^^^^^^^^
133 |                     tool_call = {
134 |                         "id": item.get("call_id") or item.get("id"),
    |

E501 Line too long (99 > 88)
   --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/llm.py:147:89
    |
146 |             if event_type in {"response.completed", "response.done"}:
147 |                 response = event.get("response") if isinstance(event.get("response"), dict) else {}
    |                                                                                         ^^^^^^^^^^^
148 |                 usage = response.get("usage") if isinstance(response, dict) else None
149 |                 yield LLMResultChunkDelta(
    |

E501 Line too long (97 > 88)
   --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/llm.py:159:89
    |
157 |             if event_type == "response.error":
158 |                 detail = event.get("error")
159 |                 raise RuntimeError(format_runtime_error("OpenAI streaming error", detail=detail))
    |                                                                                         ^^^^^^^^^
160 |
161 |     @staticmethod
    |

E501 Line too long (92 > 88)
   --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/llm.py:162:89
    |
161 |     @staticmethod
162 |     def _build_headers(credentials: dict[str, Any], stream: bool = False) -> dict[str, str]:
    |                                                                                         ^^^^
163 |         api_key = credentials.get("openai_api_key") or credentials.get("api_key")
164 |         if not isinstance(api_key, str) or not api_key.strip():
    |

E501 Line too long (97 > 88)
   --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/llm.py:177:89
    |
175 |         return headers
176 |
177 |     def _post_json(self, credentials: dict[str, Any], payload: dict[str, Any]) -> dict[str, Any]:
    |                                                                                         ^^^^^^^^^
178 |         endpoint = responses_endpoint(credentials.get("openai_api_base"))
179 |         request = urllib.request.Request(
    |

E501 Line too long (91 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/provider/openai_responses_provider.py:23:89
   |
22 |     @staticmethod
23 |     def _extract_credentials(credentials: dict[str, Any] | None) -> tuple[str, str | None]:
   |                                                                                         ^^^
24 |         values = credentials or {}
25 |         api_key = values.get("openai_api_key") or values.get("api_key")
   |

I001 [*] Import block is un-sorted or un-formatted
 --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/conftest.py:1:1
  |
1 | / from __future__ import annotations
2 | |
3 | | import sys
4 | | from pathlib import Path
  | |________________________^
  |
help: Organize imports

E501 Line too long (101 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_entrypoint.py:36:89
   |
34 |     monkeypatch.setitem(sys.modules, "dify_plugin", fake_dify_plugin)
35 |
36 |     main_path = Path(__file__).resolve().parents[2] / "app" / "openai_responses_provider" / "main.py"
   |                                                                                         ^^^^^^^^^^^^^
37 |     namespace = runpy.run_path(str(main_path), run_name="__main__")
   |

E501 Line too long (89 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_llm_streaming.py:10:89
   |
10 | def test_invoke_non_stream_sets_stream_false_and_returns_llm_result(monkeypatch) -> None:  # noqa: ANN001
   |                                                                                         ^
11 |     model = OpenAIResponsesLargeLanguageModel()
12 |     captured: dict[str, dict] = {}
   |

E501 Line too long (92 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_llm_streaming.py:33:89
   |
33 | def test_invoke_stream_sets_stream_true_and_emits_expected_chunk_shape(monkeypatch) -> None:  # noqa: ANN001
   |                                                                                         ^^^^
34 |     model = OpenAIResponsesLargeLanguageModel()
35 |     captured: dict[str, dict] = {}
   |

E501 Line too long (90 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_messages.py:74:89
   |
72 |     assert extract_tool_calls(response) == [
73 |         {"id": "call_1", "type": "function", "name": "lookup", "arguments": {"id": 42}},
74 |         {"id": "call_2", "type": "function", "name": "search", "arguments": {"q": "abc"}},
   |                                                                                         ^^
75 |     ]
   |

I001 [*] Import block is un-sorted or un-formatted
 --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_payloads.py:1:1
  |
1 | / from __future__ import annotations
2 | |
3 | | import pytest
4 | |
5 | | from openai_responses_provider.internal.payloads import build_responses_payload, coerce_strict_bool
  | |___________________________________________________________________________________________________^
  |
help: Organize imports

E501 Line too long (99 > 88)
 --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_payloads.py:5:89
  |
3 | import pytest
4 |
5 | from openai_responses_provider.internal.payloads import build_responses_payload, coerce_strict_bool
  |                                                                                         ^^^^^^^^^^^
  |

E501 Line too long (89 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_payloads.py:24:89
   |
22 |     ],
23 | )
24 | def test_coerce_strict_bool_accepts_only_supported_values(value, expected: bool) -> None:  # noqa: ANN001
   |                                                                                         ^
25 |     assert coerce_strict_bool(value, "parallel_tool_calls") is expected
   |

E501 Line too long (95 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_payloads.py:30:89
   |
28 | @pytest.mark.parametrize("value", [2, -1, "maybe", "", None, {}, []])
29 | def test_coerce_strict_bool_rejects_invalid_values(value) -> None:  # noqa: ANN001
30 |     with pytest.raises(ValueError, match="parallel_tool_calls must be a strict boolean value"):
   |                                                                                         ^^^^^^^
31 |         coerce_strict_bool(value, "parallel_tool_calls")
   |

E501 Line too long (99 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_payloads.py:35:89
   |
34 | def test_build_responses_payload_requires_json_schema_when_requested() -> None:
35 |     with pytest.raises(ValueError, match="response_format=json_schema requires valid json_schema"):
   |                                                                                         ^^^^^^^^^^^
36 |         build_responses_payload(
37 |             model="gpt-4.1-mini",
   |

E501 Line too long (95 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_payloads.py:67:89
   |
66 | def test_build_responses_payload_validates_parallel_tool_calls_strictly() -> None:
67 |     with pytest.raises(ValueError, match="parallel_tool_calls must be a strict boolean value"):
   |                                                                                         ^^^^^^^
68 |         build_responses_payload(
69 |             model="gpt-4.1-mini",
   |

I001 [*] Import block is un-sorted or un-formatted
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_provider_credentials.py:1:1
   |
 1 | / from __future__ import annotations
 2 | |
 3 | | import io
 4 | | import urllib.error
 5 | |
 6 | | import pytest
 7 | |
 8 | | from openai_responses_provider.internal.errors import ProviderCredentialError
 9 | | from openai_responses_provider.provider import openai_responses_provider as provider_module
10 | | from openai_responses_provider.provider.openai_responses_provider import OpenAIResponsesProvider
   | |________________________________________________________________________________________________^
   |
help: Organize imports

E501 Line too long (91 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_provider_credentials.py:9:89
   |
 8 | from openai_responses_provider.internal.errors import ProviderCredentialError
 9 | from openai_responses_provider.provider import openai_responses_provider as provider_module
   |                                                                                         ^^^
10 | from openai_responses_provider.provider.openai_responses_provider import OpenAIResponsesProvider
   |

E501 Line too long (96 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_provider_credentials.py:10:89
   |
 8 | from openai_responses_provider.internal.errors import ProviderCredentialError
 9 | from openai_responses_provider.provider import openai_responses_provider as provider_module
10 | from openai_responses_provider.provider.openai_responses_provider import OpenAIResponsesProvider
   |                                                                                         ^^^^^^^^
   |

UP037 [*] Remove quotes from type annotation
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_provider_credentials.py:18:28
   |
16 |         self._body = body
17 |
18 |     def __enter__(self) -> "_Response":
   |                            ^^^^^^^^^^^
19 |         return self
   |
help: Remove quotes

E501 Line too long (91 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_provider_credentials.py:56:89
   |
56 | def test_validate_provider_credentials_http_error(monkeypatch: pytest.MonkeyPatch) -> None:
   |                                                                                         ^^^
57 |     def fake_urlopen(request, timeout: int = 0):  # noqa: ANN001, ARG001
58 |         raise urllib.error.HTTPError(
   |

I001 [*] Import block is un-sorted or un-formatted
 --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_provider_yaml.py:1:1
  |
1 | / from __future__ import annotations
2 | |
3 | | import json
4 | | from pathlib import Path
  | |________________________^
  |
help: Organize imports

E501 Line too long (96 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_provider_yaml.py:29:89
   |
27 |     assert data["identity"]["name"] == "openai_responses_provider"
28 |     assert "llm" in data["supported_model_types"]
29 |     assert {"predefined-model", "customizable-model"}.issubset(set(data["configurate_methods"]))
   |                                                                                         ^^^^^^^^
30 |
31 |     provider_credentials = _credential_map(
   |

E501 Line too long (99 > 88)
  --> /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_provider_yaml.py:34:89
   |
32 |         data["provider_credential_schema"]["credential_form_schemas"]
33 |     )
34 |     model_credentials = _credential_map(data["model_credential_schema"]["credential_form_schemas"])
   |                                                                                         ^^^^^^^^^^^
35 |
36 |     assert provider_credentials["openai_api_key"]["required"] is True
   |

Found 34 errors.
[*] 8 fixable with the `--fix` option.
EXIT_CODE: 1

===== dify_package =====
CMD: dify plugin package /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider
2026/02/12 00:05:33 ERROR failed to package plugin error="Key: 'PluginDeclaration.PluginDeclarationWithoutAdvancedFields.Resource.Memory' Error:Field validation for 'Memory' failed on the 'required' tag\nKey: 'PluginDeclaration.PluginDeclarationWithoutAdvancedFields.Meta.Version' Error:Field validation for 'Version' failed on the 'required' tag\nKey: 'PluginDeclaration.PluginDeclarationWithoutAdvancedFields.Meta.Arch' Error:Field validation for 'Arch' failed on the 'required' tag\nKey: 'PluginDeclaration.PluginDeclarationWithoutAdvancedFields.Meta.Runner.Language' Error:Field validation for 'Language' failed on the 'required' tag\nKey: 'PluginDeclaration.PluginDeclarationWithoutAdvancedFields.Meta.Runner.Version' Error:Field validation for 'Version' failed on the 'required' tag\nKey: 'PluginDeclaration.PluginDeclarationWithoutAdvancedFields.Meta.Runner.Entrypoint' Error:Field validation for 'Entrypoint' failed on the 'required' tag\nKey: 'PluginDeclaration.PluginDeclarationWithoutAdvancedFields.CreatedAt' Error:Field validation for 'CreatedAt' failed on the 'required' tag"
EXIT_CODE: 1

===== pytest_no_cov =====
CMD: uv run pytest -q --no-cov /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider
F.FF..........................                                           [100%]
=================================== FAILURES ===================================
____________ test_main_module_exposes_plugin_with_provider_package _____________

self = <dify_plugin.core.plugin_registration.PluginRegistration object at 0x7c4025ceb2f0>

    def _load_plugin_configuration(self):
        """
        load basic plugin configuration from manifest.yaml
        """
        try:
            file = load_yaml_file("manifest.yaml")
>           self.configuration = PluginConfiguration(**file)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           pydantic_core._pydantic_core.ValidationError: 11 validation errors for PluginConfiguration
E           version
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           type
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           author
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           name
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           description
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           icon
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           label
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           created_at
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           resource
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           plugins
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           meta
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing

.venv/lib/python3.12/site-packages/dify_plugin/core/plugin_registration.py:136: ValidationError

The above exception was the direct cause of the following exception:

    def test_main_module_exposes_plugin_with_provider_package() -> None:
>       module = importlib.import_module("openai_responses_provider.main")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_entrypoint.py:11: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/importlib/__init__.py:90: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:999: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
/tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/main.py:18: in <module>
    plugin = Plugin(DifyPluginEnv(provider_package="openai_responses_provider"))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/dify_plugin/plugin.py:48: in __init__
    self.registration = PluginRegistration(config)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/dify_plugin/core/plugin_registration.py:113: in __init__
    self._load_plugin_configuration()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <dify_plugin.core.plugin_registration.PluginRegistration object at 0x7c4025ceb2f0>

    def _load_plugin_configuration(self):
        """
        load basic plugin configuration from manifest.yaml
        """
        try:
            file = load_yaml_file("manifest.yaml")
            self.configuration = PluginConfiguration(**file)
    
            for provider in self.configuration.plugins.tools:
                fs = load_yaml_file(provider)
                tool_provider_configuration = ToolProviderConfiguration(**fs)
                self.tools_configuration.append(tool_provider_configuration)
            for provider in self.configuration.plugins.models:
                fs = load_yaml_file(provider)
                model_provider_configuration = ModelProviderConfiguration(**fs)
                self.models_configuration.append(model_provider_configuration)
            for provider in self.configuration.plugins.endpoints:
                fs = load_yaml_file(provider)
                endpoint_configuration = EndpointProviderConfiguration(**fs)
                self.endpoints_configuration.append(endpoint_configuration)
            for provider in self.configuration.plugins.agent_strategies:
                fs = load_yaml_file(provider)
                agent_provider_configuration = AgentStrategyProviderConfiguration(**fs)
                self.agent_strategies_configuration.append(agent_provider_configuration)
            for provider in self.configuration.plugins.datasources:
                fs = load_yaml_file(provider)
                datasource_provider_configuration = DatasourceProviderManifest(**fs)
                self.datasource_configuration.append(datasource_provider_configuration)
            for provider in self.configuration.plugins.triggers:
                fs = load_yaml_file(provider)
                trigger_provider_configuration = TriggerProviderConfiguration(**fs)
                self.triggers_configuration.append(trigger_provider_configuration)
    
        except Exception as e:
>           raise ValueError(f"Error loading plugin configuration: {e!s}") from e
E           ValueError: Error loading plugin configuration: 11 validation errors for PluginConfiguration
E           version
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           type
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           author
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           name
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           description
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           icon
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           label
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           created_at
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           resource
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           plugins
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           meta
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing

.venv/lib/python3.12/site-packages/dify_plugin/core/plugin_registration.py:164: ValueError
_______ test_invoke_non_stream_sets_stream_false_and_returns_llm_result ________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7c4025b078f0>

    def test_invoke_non_stream_sets_stream_false_and_returns_llm_result(monkeypatch) -> None:  # noqa: ANN001
>       model = OpenAIResponsesLargeLanguageModel()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: Can't instantiate abstract class OpenAIResponsesLargeLanguageModel without an implementation for abstract methods '_invoke', '_invoke_error_mapping'

/tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_llm_streaming.py:11: TypeError
______ test_invoke_stream_sets_stream_true_and_emits_expected_chunk_shape ______

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7c4025b07cb0>

    def test_invoke_stream_sets_stream_true_and_emits_expected_chunk_shape(monkeypatch) -> None:  # noqa: ANN001
>       model = OpenAIResponsesLargeLanguageModel()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: Can't instantiate abstract class OpenAIResponsesLargeLanguageModel without an implementation for abstract methods '_invoke', '_invoke_error_mapping'

/tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_llm_streaming.py:34: TypeError
=============================== warnings summary ===============================
.venv/lib/python3.12/site-packages/dify_plugin/__init__.py:4
  /home/devuser/workspace/.venv/lib/python3.12/site-packages/dify_plugin/__init__.py:4: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/home/devuser/workspace/.venv/lib/python3.12/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/home/devuser/workspace/.venv/lib/python3.12/site-packages/urllib3/util/ssl_.py)', 'anyio.streams.tls (/home/devuser/workspace/.venv/lib/python3.12/site-packages/anyio/streams/tls.py)']. 
    monkey.patch_all(sys=True)

.venv/lib/python3.12/site-packages/dify_plugin/entities/provider_config.py:88
  /home/devuser/workspace/.venv/lib/python3.12/site-packages/dify_plugin/entities/provider_config.py:88: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class ProviderConfig(BaseModel):

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_entrypoint.py::test_main_module_exposes_plugin_with_provider_package
FAILED ../../../tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_llm_streaming.py::test_invoke_non_stream_sets_stream_false_and_returns_llm_result
FAILED ../../../tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_llm_streaming.py::test_invoke_stream_sets_stream_true_and_emits_expected_chunk_shape
3 failed, 27 passed, 2 warnings in 0.75s
EXIT_CODE: 1

===== pytest_with_cov =====
CMD: uv run pytest -q /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider
F.FF..........................                                           [100%]
=================================== FAILURES ===================================
____________ test_main_module_exposes_plugin_with_provider_package _____________

self = <dify_plugin.core.plugin_registration.PluginRegistration object at 0x79ec1c461730>

    def _load_plugin_configuration(self):
        """
        load basic plugin configuration from manifest.yaml
        """
        try:
            file = load_yaml_file("manifest.yaml")
>           self.configuration = PluginConfiguration(**file)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           pydantic_core._pydantic_core.ValidationError: 11 validation errors for PluginConfiguration
E           version
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           type
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           author
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           name
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           description
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           icon
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           label
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           created_at
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           resource
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           plugins
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           meta
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing

.venv/lib/python3.12/site-packages/dify_plugin/core/plugin_registration.py:136: ValidationError

The above exception was the direct cause of the following exception:

    def test_main_module_exposes_plugin_with_provider_package() -> None:
>       module = importlib.import_module("openai_responses_provider.main")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_entrypoint.py:11: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/importlib/__init__.py:90: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:999: in exec_module
    ???
<frozen importlib._bootstrap>:488: in _call_with_frames_removed
    ???
/tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/main.py:18: in <module>
    plugin = Plugin(DifyPluginEnv(provider_package="openai_responses_provider"))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/dify_plugin/plugin.py:48: in __init__
    self.registration = PluginRegistration(config)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.12/site-packages/dify_plugin/core/plugin_registration.py:113: in __init__
    self._load_plugin_configuration()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <dify_plugin.core.plugin_registration.PluginRegistration object at 0x79ec1c461730>

    def _load_plugin_configuration(self):
        """
        load basic plugin configuration from manifest.yaml
        """
        try:
            file = load_yaml_file("manifest.yaml")
            self.configuration = PluginConfiguration(**file)
    
            for provider in self.configuration.plugins.tools:
                fs = load_yaml_file(provider)
                tool_provider_configuration = ToolProviderConfiguration(**fs)
                self.tools_configuration.append(tool_provider_configuration)
            for provider in self.configuration.plugins.models:
                fs = load_yaml_file(provider)
                model_provider_configuration = ModelProviderConfiguration(**fs)
                self.models_configuration.append(model_provider_configuration)
            for provider in self.configuration.plugins.endpoints:
                fs = load_yaml_file(provider)
                endpoint_configuration = EndpointProviderConfiguration(**fs)
                self.endpoints_configuration.append(endpoint_configuration)
            for provider in self.configuration.plugins.agent_strategies:
                fs = load_yaml_file(provider)
                agent_provider_configuration = AgentStrategyProviderConfiguration(**fs)
                self.agent_strategies_configuration.append(agent_provider_configuration)
            for provider in self.configuration.plugins.datasources:
                fs = load_yaml_file(provider)
                datasource_provider_configuration = DatasourceProviderManifest(**fs)
                self.datasource_configuration.append(datasource_provider_configuration)
            for provider in self.configuration.plugins.triggers:
                fs = load_yaml_file(provider)
                trigger_provider_configuration = TriggerProviderConfiguration(**fs)
                self.triggers_configuration.append(trigger_provider_configuration)
    
        except Exception as e:
>           raise ValueError(f"Error loading plugin configuration: {e!s}") from e
E           ValueError: Error loading plugin configuration: 11 validation errors for PluginConfiguration
E           version
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           type
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           author
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           name
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           description
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           icon
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           label
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           created_at
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           resource
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           plugins
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing
E           meta
E             Field required [type=missing, input_value={}, input_type=dict]
E               For further information visit https://errors.pydantic.dev/2.12/v/missing

.venv/lib/python3.12/site-packages/dify_plugin/core/plugin_registration.py:164: ValueError
_______ test_invoke_non_stream_sets_stream_false_and_returns_llm_result ________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x79ec1c37ff50>

    def test_invoke_non_stream_sets_stream_false_and_returns_llm_result(monkeypatch) -> None:  # noqa: ANN001
>       model = OpenAIResponsesLargeLanguageModel()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: Can't instantiate abstract class OpenAIResponsesLargeLanguageModel without an implementation for abstract methods '_invoke', '_invoke_error_mapping'

/tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_llm_streaming.py:11: TypeError
______ test_invoke_stream_sets_stream_true_and_emits_expected_chunk_shape ______

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x79ec1c37fcb0>

    def test_invoke_stream_sets_stream_true_and_emits_expected_chunk_shape(monkeypatch) -> None:  # noqa: ANN001
>       model = OpenAIResponsesLargeLanguageModel()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       TypeError: Can't instantiate abstract class OpenAIResponsesLargeLanguageModel without an implementation for abstract methods '_invoke', '_invoke_error_mapping'

/tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_llm_streaming.py:34: TypeError
=============================== warnings summary ===============================
.venv/lib/python3.12/site-packages/dify_plugin/__init__.py:4
  /home/devuser/workspace/.venv/lib/python3.12/site-packages/dify_plugin/__init__.py:4: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['anyio.streams.tls (/home/devuser/workspace/.venv/lib/python3.12/site-packages/anyio/streams/tls.py)', 'urllib3.util (/home/devuser/workspace/.venv/lib/python3.12/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/home/devuser/workspace/.venv/lib/python3.12/site-packages/urllib3/util/ssl_.py)']. 
    monkey.patch_all(sys=True)

.venv/lib/python3.12/site-packages/dify_plugin/entities/provider_config.py:88
  /home/devuser/workspace/.venv/lib/python3.12/site-packages/dify_plugin/entities/provider_config.py:88: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class ProviderConfig(BaseModel):

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../../../tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_entrypoint.py::test_main_module_exposes_plugin_with_provider_package
FAILED ../../../tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_llm_streaming.py::test_invoke_non_stream_sets_stream_false_and_returns_llm_result
FAILED ../../../tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_llm_streaming.py::test_invoke_stream_sets_stream_true_and_emits_expected_chunk_shape
3 failed, 27 passed, 2 warnings in 0.72s
EXIT_CODE: 1

===== diff_app =====
CMD: diff -rq -x __pycache__ -x *.pyc /home/devuser/workspace/app/openai_gpt5_responses /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider
Only in /home/devuser/workspace/app/openai_gpt5_responses: .env
Files /home/devuser/workspace/app/openai_gpt5_responses/.env.example and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/.env.example differ
Files /home/devuser/workspace/app/openai_gpt5_responses/PRIVACY.md and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/PRIVACY.md differ
Files /home/devuser/workspace/app/openai_gpt5_responses/README.md and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/README.md differ
Files /home/devuser/workspace/app/openai_gpt5_responses/__init__.py and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/__init__.py differ
Files /home/devuser/workspace/app/openai_gpt5_responses/_assets/icon.svg and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/_assets/icon.svg differ
Only in /home/devuser/workspace/app/openai_gpt5_responses: icon.svg
Files /home/devuser/workspace/app/openai_gpt5_responses/internal/__init__.py and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/internal/__init__.py differ
Files /home/devuser/workspace/app/openai_gpt5_responses/internal/credentials.py and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/internal/credentials.py differ
Files /home/devuser/workspace/app/openai_gpt5_responses/internal/errors.py and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/internal/errors.py differ
Files /home/devuser/workspace/app/openai_gpt5_responses/internal/messages.py and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/internal/messages.py differ
Files /home/devuser/workspace/app/openai_gpt5_responses/internal/payloads.py and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/internal/payloads.py differ
Files /home/devuser/workspace/app/openai_gpt5_responses/main.py and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/main.py differ
Files /home/devuser/workspace/app/openai_gpt5_responses/manifest.yaml and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/manifest.yaml differ
Files /home/devuser/workspace/app/openai_gpt5_responses/models/__init__.py and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/__init__.py differ
Files /home/devuser/workspace/app/openai_gpt5_responses/models/llm/__init__.py and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/__init__.py differ
Only in /home/devuser/workspace/app/openai_gpt5_responses/models/llm: _position.yaml
Only in /home/devuser/workspace/app/openai_gpt5_responses/models/llm: gpt-5-codex.yaml
Only in /home/devuser/workspace/app/openai_gpt5_responses/models/llm: gpt-5-mini.yaml
Only in /home/devuser/workspace/app/openai_gpt5_responses/models/llm: gpt-5-nano.yaml
Only in /home/devuser/workspace/app/openai_gpt5_responses/models/llm: gpt-5.1-codex.yaml
Only in /home/devuser/workspace/app/openai_gpt5_responses/models/llm: gpt-5.2-pro.yaml
Only in /home/devuser/workspace/app/openai_gpt5_responses/models/llm: gpt-5.2.yaml
Only in /home/devuser/workspace/app/openai_gpt5_responses/models/llm: gpt-5.3-codex.yaml
Only in /home/devuser/workspace/app/openai_gpt5_responses/models/llm: gpt-5.yaml
Files /home/devuser/workspace/app/openai_gpt5_responses/models/llm/llm.py and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/models/llm/llm.py differ
Files /home/devuser/workspace/app/openai_gpt5_responses/provider/__init__.py and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/provider/__init__.py differ
Only in /home/devuser/workspace/app/openai_gpt5_responses/provider: openai_gpt5.py
Only in /home/devuser/workspace/app/openai_gpt5_responses/provider: openai_gpt5.yaml
Only in /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/provider: openai_responses_provider.py
Only in /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/provider: openai_responses_provider.yaml
Files /home/devuser/workspace/app/openai_gpt5_responses/requirements.txt and /tmp/openai_responses_provider_subagent_20260211_235302/app/openai_responses_provider/requirements.txt differ
EXIT_CODE: 1

===== diff_tests =====
CMD: diff -rq -x __pycache__ -x *.pyc /home/devuser/workspace/tests/openai_gpt5_responses /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider
Only in /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider: .pytest_cache
Only in /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider: conftest.py
Only in /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider: test_entrypoint.py
Only in /home/devuser/workspace/tests/openai_gpt5_responses: test_entrypoints_and_errors.py
Only in /home/devuser/workspace/tests/openai_gpt5_responses: test_llm_stream_flag.py
Only in /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider: test_llm_streaming.py
Files /home/devuser/workspace/tests/openai_gpt5_responses/test_messages.py and /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_messages.py differ
Files /home/devuser/workspace/tests/openai_gpt5_responses/test_payloads.py and /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_payloads.py differ
Only in /home/devuser/workspace/tests/openai_gpt5_responses: test_payloads_bool_coercion.py
Only in /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider: test_provider_credentials.py
Only in /home/devuser/workspace/tests/openai_gpt5_responses: test_provider_runtime.py
Only in /home/devuser/workspace/tests/openai_gpt5_responses: test_provider_schema.py
Only in /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider: test_provider_yaml.py
EXIT_CODE: 1

===== wc_line_count =====
CMD: bash -lc wc -l /home/devuser/workspace/tests/openai_gpt5_responses/*.py /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/*.py
  108 /home/devuser/workspace/tests/openai_gpt5_responses/test_entrypoints_and_errors.py
  842 /home/devuser/workspace/tests/openai_gpt5_responses/test_llm_stream_flag.py
  246 /home/devuser/workspace/tests/openai_gpt5_responses/test_messages.py
   74 /home/devuser/workspace/tests/openai_gpt5_responses/test_payloads.py
  130 /home/devuser/workspace/tests/openai_gpt5_responses/test_payloads_bool_coercion.py
  155 /home/devuser/workspace/tests/openai_gpt5_responses/test_provider_runtime.py
  151 /home/devuser/workspace/tests/openai_gpt5_responses/test_provider_schema.py
   11 /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/conftest.py
   40 /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_entrypoint.py
   83 /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_llm_streaming.py
   75 /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_messages.py
   72 /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_payloads.py
   70 /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_provider_credentials.py
   49 /tmp/openai_responses_provider_subagent_20260211_235302/tests/openai_responses_provider/test_provider_yaml.py
 2106 total
EXIT_CODE: 0

